{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13911847,"sourceType":"datasetVersion","datasetId":8864307},{"sourceId":13923531,"sourceType":"datasetVersion","datasetId":8872563}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom datasets import Dataset\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\nimport time\nfrom transformers import TrainerCallback\nimport torch\nfrom transformers import pipeline\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T21:55:51.167138Z","iopub.execute_input":"2025-11-29T21:55:51.167600Z","iopub.status.idle":"2025-11-29T21:56:20.102648Z","shell.execute_reply.started":"2025-11-29T21:55:51.167574Z","shell.execute_reply":"2025-11-29T21:56:20.102033Z"}},"outputs":[{"name":"stderr","text":"2025-11-29 21:56:03.782337: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764453363.963778      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764453364.016281      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":1},{"cell_type":"markdown","source":"rubert-base-cased-conversational\nConversational RuBERT (Russian, cased, 12‚Äëlayer, 768‚Äëhidden, 12‚Äëheads, 180M parameters) was trained on OpenSubtitles[1], Dirty, Pikabu, and a Social Media segment of Taiga corpus[2]. We assembled a new vocabulary for Conversational RuBERT model on this data and initialized the model with RuBERT.\n\n08.11.2021: upload model with MLM and NSP heads\n\n[1]: P. Lison and J. Tiedemann, 2016, OpenSubtitles2016: Extracting Large Parallel Corpora from Movie and TV Subtitles. In Proceedings of the 10th International Conference on Language Resources and Evaluation (LREC 2016)\n\n[2]: Shavrina T., Shapovalova O. (2017) TO THE METHODOLOGY OF CORPUS CONSTRUCTION FOR MACHINE LEARNING: ¬´TAIGA¬ª SYNTAX TREE CORPUS AND PARSER. in proc. of ‚ÄúCORPORA2017‚Äù, international conference , Saint-Petersbourg, 2017.","metadata":{}},{"cell_type":"code","source":"# =========================\n# 1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•\n# =========================\ndf = pd.read_csv(\"/kaggle/input/hack-data/train.csv\")  \n\n\ndf = df.sample(frac=1).reset_index(drop=True)  # shuffle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T21:56:50.634223Z","iopub.execute_input":"2025-11-29T21:56:50.634910Z","iopub.status.idle":"2025-11-29T21:56:54.539839Z","shell.execute_reply.started":"2025-11-29T21:56:50.634882Z","shell.execute_reply":"2025-11-29T21:56:54.538985Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train_df, temp_df = train_test_split(\n    df,\n    test_size=0.2,  \n    stratify=df[\"label\"],\n    random_state=42\n)\n\nval_df, test_df = train_test_split(\n    temp_df,\n    test_size=0.5,              \n    stratify=temp_df[\"label\"], \n    random_state=42\n)\n\ntrain_ds = Dataset.from_pandas(train_df)\nval_ds = Dataset.from_pandas(val_df)\ntest_ds = Dataset.from_pandas(test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T21:57:19.477223Z","iopub.execute_input":"2025-11-29T21:57:19.478007Z","iopub.status.idle":"2025-11-29T21:57:20.750554Z","shell.execute_reply.started":"2025-11-29T21:57:19.477980Z","shell.execute_reply":"2025-11-29T21:57:20.749724Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"rubert-base-cased-conversational Conversational RuBERT (Russian, cased, 12‚Äëlayer, 768‚Äëhidden, 12‚Äëheads, 180M parameters) was trained on OpenSubtitles[1], Dirty, Pikabu, and a Social Media segment of Taiga corpus[2]. We assembled a new vocabulary for Conversational RuBERT model on this data and initialized the model with RuBERT.\n\n08.11.2021: upload model with MLM and NSP heads\n\n[1]: P. Lison and J. Tiedemann, 2016, OpenSubtitles2016: Extracting Large Parallel Corpora from Movie and TV Subtitles. In Proceedings of the 10th International Conference on Language Resources and Evaluation (LREC 2016)\n\n[2]: Shavrina T., Shapovalova O. (2017) TO THE METHODOLOGY OF CORPUS CONSTRUCTION FOR MACHINE LEARNING: ¬´TAIGA¬ª SYNTAX TREE CORPUS AND PARSER. in proc. of ‚ÄúCORPORA2017‚Äù, international conference , Saint-Petersbourg, 2017.","metadata":{}},{"cell_type":"code","source":"MODEL_NAME = \"DeepPavlov/rubert-base-cased-conversational\"\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\ndef tokenize(batch):\n    return tokenizer(\n        batch[\"text\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=256\n    )\n\ntrain_ds = train_ds.map(tokenize, batched=True)\nval_ds = val_ds.map(tokenize, batched=True)\n\ntrain_ds = train_ds.remove_columns([\"text\"])\nval_ds = val_ds.remove_columns([\"text\"])\n\ntrain_ds.set_format(\"torch\")\nval_ds.set_format(\"torch\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T21:59:07.709021Z","iopub.execute_input":"2025-11-29T21:59:07.709837Z","iopub.status.idle":"2025-11-29T22:00:00.729735Z","shell.execute_reply.started":"2025-11-29T21:59:07.709802Z","shell.execute_reply":"2025-11-29T22:00:00.729167Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6423c5e8750d484bbb5c84cb8bcea32e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6a1a3ff682542f9bcfe0d336741d27c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8b8825376cc49f7b78058dcaaf1c7f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdd6096229fb43eca0df612c0f581281"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/185892 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f43ed3a78c64d329a72ad6b939d41fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/23237 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6c101cfb2974e50a70594980af5d4c2"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=3  # 0,1,2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T22:00:04.555487Z","iopub.execute_input":"2025-11-29T22:00:04.555805Z","iopub.status.idle":"2025-11-29T22:00:10.190902Z","shell.execute_reply.started":"2025-11-29T22:00:04.555781Z","shell.execute_reply":"2025-11-29T22:00:10.190171Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"551d1873518e4b50984a389535cefa5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"697c90b518cf4aec97284d3520dcf53b"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=1)\n\n    return {\n        \"accuracy\": accuracy_score(labels, preds),\n        \"f1_macro\": f1_score(labels, preds, average=\"macro\")\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T22:00:28.459584Z","iopub.execute_input":"2025-11-29T22:00:28.460260Z","iopub.status.idle":"2025-11-29T22:00:28.464637Z","shell.execute_reply.started":"2025-11-29T22:00:28.460230Z","shell.execute_reply":"2025-11-29T22:00:28.463889Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# =========================\n# 5. –ü–ê–†–ê–ú–ï–¢–†–´ –û–ë–£–ß–ï–ù–ò–Ø\n# =========================\n# training_args = TrainingArguments(\n#     output_dir=\"/kaggle/working/rubert_sentiment\",\n#     eval_strategy=\"epoch\",\n#     save_strategy=\"epoch\",\n#     learning_rate=2e-5,\n#     per_device_train_batch_size=16,\n#     per_device_eval_batch_size=16,\n#     num_train_epochs=1,\n#     weight_decay=0.01,\n#     logging_dir=\"./logs\",\n#     load_best_model_at_end=True,\n#     metric_for_best_model=\"f1_macro\",\n    \n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T22:03:07.988036Z","iopub.execute_input":"2025-11-28T22:03:07.988290Z","iopub.status.idle":"2025-11-28T22:03:08.002062Z","shell.execute_reply.started":"2025-11-28T22:03:07.988268Z","shell.execute_reply":"2025-11-28T22:03:08.001336Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# 5. –ü–ê–†–ê–ú–ï–¢–†–´ –û–ë–£–ß–ï–ù–ò–Ø\n# =========================\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/rubert_sentiment\",\n    eval_strategy=\"steps\",\n    eval_steps=500,\n    \n    save_strategy=\"steps\",\n    save_steps=1000,\n    \n    logging_strategy=\"steps\",\n    logging_steps=1000,\n    logging_first_step=True,\n    \n    learning_rate=2e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=1,\n    weight_decay=0.01,\n    metric_for_best_model=\"f1_macro\",\n\n    save_total_limit=1,\n    save_only_model=True,\n    load_best_model_at_end=True,\n    no_cuda=False,\n    \n    logging_dir=None,\n    report_to=\"none\",\n    \n    dataloader_pin_memory=True,\n    dataloader_num_workers=2,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T22:09:12.058777Z","iopub.execute_input":"2025-11-29T22:09:12.059498Z","iopub.status.idle":"2025-11-29T22:09:12.087976Z","shell.execute_reply.started":"2025-11-29T22:09:12.059470Z","shell.execute_reply":"2025-11-29T22:09:12.087323Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=val_ds,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T22:09:24.630987Z","iopub.execute_input":"2025-11-29T22:09:24.631690Z","iopub.status.idle":"2025-11-29T22:09:25.018795Z","shell.execute_reply.started":"2025-11-29T22:09:24.631651Z","shell.execute_reply":"2025-11-29T22:09:25.018170Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/1092916359.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"class ProgressCheckerCallback(TrainerCallback):\n    def on_step_begin(self, args, state, control, **kwargs):\n        if state.global_step % 1000 == 0:\n            print(f\"üîπ –ü—Ä–æ–≥—Ä–µ—Å—Å: —à–∞–≥ {state.global_step}, —ç–ø–æ—Ö–∞ {state.epoch:.1f}\", flush=True)\n    \n    def on_train_begin(self, args, state, control, **kwargs):\n        print(\"–û–±—É—á–µ–Ω–∏–µ –ù–ê–ß–ê–õ–û–°–¨!\", flush=True)\n    \n    def on_step_end(self, args, state, control, **kwargs):\n        # –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥ –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥\n        if hasattr(self, 'last_print'):\n            if time.time() - self.last_print > 3600:\n                print(f\"–ê–∫—Ç–∏–≤–Ω–æ –æ–±—É—á–∞–µ—Ç—Å—è... —à–∞–≥ {state.global_step}\", flush=True)\n                self.last_print = time.time()\n        else:\n            self.last_print = time.time()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T13:07:12.295717Z","iopub.execute_input":"2025-11-29T13:07:12.296007Z","iopub.status.idle":"2025-11-29T13:07:12.302070Z","shell.execute_reply.started":"2025-11-29T13:07:12.295987Z","shell.execute_reply":"2025-11-29T13:07:12.301266Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=val_ds,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    callbacks=[ProgressCheckerCallback()]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T13:07:17.091076Z","iopub.execute_input":"2025-11-29T13:07:17.091985Z","iopub.status.idle":"2025-11-29T13:07:17.104374Z","shell.execute_reply.started":"2025-11-29T13:07:17.091952Z","shell.execute_reply":"2025-11-29T13:07:17.103582Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/1212326759.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T13:07:21.261529Z","iopub.execute_input":"2025-11-29T13:07:21.261786Z","iopub.status.idle":"2025-11-29T15:03:34.312268Z","shell.execute_reply.started":"2025-11-29T13:07:21.261769Z","shell.execute_reply":"2025-11-29T15:03:34.311486Z"}},"outputs":[{"name":"stdout","text":"üéØ –û–±—É—á–µ–Ω–∏–µ –ù–ê–ß–ê–õ–û–°–¨!\nüîπ –ü—Ä–æ–≥—Ä–µ—Å—Å: —à–∞–≥ 0, —ç–ø–æ—Ö–∞ 0.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5810' max='5810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5810/5810 1:56:11, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.152100</td>\n      <td>0.603310</td>\n      <td>0.733098</td>\n      <td>0.731142</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.635400</td>\n      <td>0.582738</td>\n      <td>0.743039</td>\n      <td>0.741786</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.635400</td>\n      <td>0.568565</td>\n      <td>0.751861</td>\n      <td>0.752625</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.575800</td>\n      <td>0.559749</td>\n      <td>0.751646</td>\n      <td>0.749541</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.575800</td>\n      <td>0.554814</td>\n      <td>0.752808</td>\n      <td>0.751764</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.558000</td>\n      <td>0.543925</td>\n      <td>0.755907</td>\n      <td>0.757262</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.558000</td>\n      <td>0.543965</td>\n      <td>0.758704</td>\n      <td>0.760996</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.548700</td>\n      <td>0.533690</td>\n      <td>0.762491</td>\n      <td>0.765050</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.548700</td>\n      <td>0.531868</td>\n      <td>0.767354</td>\n      <td>0.768245</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.531500</td>\n      <td>0.525866</td>\n      <td>0.768903</td>\n      <td>0.767910</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.531500</td>\n      <td>0.524707</td>\n      <td>0.770151</td>\n      <td>0.770440</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"üîπ –ü—Ä–æ–≥—Ä–µ—Å—Å: —à–∞–≥ 1000, —ç–ø–æ—Ö–∞ 0.2\nüîπ –ü—Ä–æ–≥—Ä–µ—Å—Å: —à–∞–≥ 2000, —ç–ø–æ—Ö–∞ 0.3\nüîπ –ü—Ä–æ–≥—Ä–µ—Å—Å: —à–∞–≥ 3000, —ç–ø–æ—Ö–∞ 0.5\n‚è±Ô∏è  –ê–∫—Ç–∏–≤–Ω–æ –æ–±—É—á–∞–µ—Ç—Å—è... —à–∞–≥ 3001\nüîπ –ü—Ä–æ–≥—Ä–µ—Å—Å: —à–∞–≥ 4000, —ç–ø–æ—Ö–∞ 0.7\nüîπ –ü—Ä–æ–≥—Ä–µ—Å—Å: —à–∞–≥ 5000, —ç–ø–æ—Ö–∞ 0.9\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=5810, training_loss=0.5645842586450035, metrics={'train_runtime': 6972.5437, 'train_samples_per_second': 26.661, 'train_steps_per_second': 0.833, 'total_flos': 2.445533972414669e+16, 'train_loss': 0.5645842586450035, 'epoch': 1.0})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"trainer.save_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T03:20:24.470517Z","iopub.execute_input":"2025-11-29T03:20:24.471331Z","iopub.status.idle":"2025-11-29T03:20:24.534527Z","shell.execute_reply.started":"2025-11-29T03:20:24.471294Z","shell.execute_reply":"2025-11-29T03:20:24.533608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å–∫–∏\nmodel = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/input/my-model/rubert_sentiment_v2\")\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/my-model/rubert_sentiment_v2\")\n\n\ntexts = test_df[\"text\"].astype(str).tolist()\ntrue_labels = test_df[\"label\"].astype(int).tolist()\n\ndevice = 0 if torch.cuda.is_available() else -1\n\nclassifier = pipeline(\n    \"sentiment-analysis\",\n    model=model,\n    tokenizer=tokenizer,\n    device=device,\n    max_length=512\n)\n\nlabel_map = {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n}\n\npred_labels = []\nfor text in tqdm(texts):\n    result = classifier(text, truncation=True)[0][\"label\"]\n    pred_labels.append(label_map[result])\n\nacc = accuracy_score(true_labels, pred_labels)\nf1_macro = f1_score(true_labels, pred_labels, average=\"macro\")\n\nprint(\"\\n‚úÖ RESULTS\")\nprint(f\"Accuracy:  {acc:.4f}\")\nprint(f\"F1-macro:  {f1_macro:.4f}\")\n\nprint(\"\\nüìä CLASSIFICATION REPORT:\")\nprint(classification_report(true_labels, pred_labels, target_names=[\"NEGATIVE\", \"NEUTRAL\", \"POSITIVE\"]))\n\nprint(\"\\nüßÆ CONFUSION MATRIX:\")\nprint(confusion_matrix(true_labels, pred_labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T18:51:19.595339Z","iopub.execute_input":"2025-11-29T18:51:19.595645Z","iopub.status.idle":"2025-11-29T18:55:00.866965Z","shell.execute_reply.started":"2025-11-29T18:51:19.595622Z","shell.execute_reply":"2025-11-29T18:55:00.866307Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23237/23237 [03:26<00:00, 112.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ RESULTS\nAccuracy:  0.7997\nF1-macro:  0.7996\n\nüìä CLASSIFICATION REPORT:\n              precision    recall  f1-score   support\n\n    NEGATIVE       0.71      0.72      0.72      7725\n     NEUTRAL       0.88      0.89      0.89      7749\n    POSITIVE       0.80      0.79      0.80      7763\n\n    accuracy                           0.80     23237\n   macro avg       0.80      0.80      0.80     23237\nweighted avg       0.80      0.80      0.80     23237\n\n\nüßÆ CONFUSION MATRIX:\n[[5557  782 1386]\n [ 741 6879  129]\n [1487  130 6146]]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# **–ü–æ–ø—ã—Ç–∫–∞ –ø—Ä–æ–≥–æ–Ω–∞ –≥–æ—Ç–æ–≤–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom transformers import pipeline\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T22:17:46.480292Z","iopub.execute_input":"2025-11-29T22:17:46.480988Z","iopub.status.idle":"2025-11-29T22:17:46.485434Z","shell.execute_reply.started":"2025-11-29T22:17:46.480963Z","shell.execute_reply":"2025-11-29T22:17:46.484407Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# ============================\n# 1. –ó–ê–ì–†–£–ñ–ê–ï–ú –î–ê–ù–ù–´–ï\n# ============================\n\n# df = pd.read_csv(\"/kaggle/input/hack-data/train.csv\")\n# texts = test_df[\"text\"].astype(str).tolist()\n# true_labels = test_df[\"label\"].astype(int).tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T22:18:37.572577Z","iopub.execute_input":"2025-11-29T22:18:37.572903Z","iopub.status.idle":"2025-11-29T22:18:37.581528Z","shell.execute_reply.started":"2025-11-29T22:18:37.572868Z","shell.execute_reply":"2025-11-29T22:18:37.580805Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# ============================\n# 2. –°–û–ó–î–ê–Å–ú PIPELINE\n# ============================\n\nMODEL_NAME = \"blanchefort/rubert-base-cased-sentiment\"\n\ndevice = 0 if torch.cuda.is_available() else -1\n\nblanch_classifier = pipeline(\n    \"sentiment-analysis\",\n    model=MODEL_NAME,\n    tokenizer=MODEL_NAME,\n    device=device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T22:18:05.307310Z","iopub.execute_input":"2025-11-29T22:18:05.308233Z","iopub.status.idle":"2025-11-29T22:18:09.963630Z","shell.execute_reply.started":"2025-11-29T22:18:05.308202Z","shell.execute_reply":"2025-11-29T22:18:09.962990Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/943 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a51aae1dd185424db3681015c13d7003"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/711M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1c088797928472aa00732dbd14b3ea8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/499 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94bbff8f89f5456ea07aac957e2aae88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bb5a75d6eb841eb8bef48278fbc8fff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f70a3aa3156d49ffa45b847135aca484"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# ============================\n# 3. –ü–†–û–ì–û–ù –ú–û–î–ï–õ–ò\n# ============================\nblanch_pred_labels = []\n\nblanch_label_map = {\n    \"NEGATIVE\": 0,\n    \"NEUTRAL\": 1,\n    \"POSITIVE\": 2\n}\n\nprint(\"–ó–∞–ø—É—Å–∫ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞...\")\n\nfor text in tqdm(texts):\n    result = blanch_classifier(text, truncation=True)[0][\"label\"]\n    blanch_pred_labels.append(blanch_label_map[result])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T22:18:50.849661Z","iopub.execute_input":"2025-11-29T22:18:50.850702Z","iopub.status.idle":"2025-11-29T22:22:40.638050Z","shell.execute_reply.started":"2025-11-29T22:18:50.850665Z","shell.execute_reply":"2025-11-29T22:22:40.637235Z"}},"outputs":[{"name":"stdout","text":"–ó–∞–ø—É—Å–∫ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞...\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/23237 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n  0%|          | 10/23237 [00:00<13:53, 27.88it/s] You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23237/23237 [03:49<00:00, 101.13it/s]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"acc = accuracy_score(true_labels, blanch_pred_labels)\nf1_macro = f1_score(true_labels, blanch_pred_labels, average=\"macro\")\n\nprint(\"\\n‚úÖ RESULTS\")\nprint(f\"Accuracy:  {acc:.4f}\")\nprint(f\"F1-macro:  {f1_macro:.4f}\")\n\nprint(\"\\nüìä CLASSIFICATION REPORT:\")\nprint(classification_report(true_labels, blanch_pred_labels, target_names=[\"NEGATIVE\", \"NEUTRAL\", \"POSITIVE\"]))\n\nprint(\"\\nüßÆ CONFUSION MATRIX:\")\nprint(confusion_matrix(true_labels, blanch_pred_labels))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T22:23:05.964974Z","iopub.execute_input":"2025-11-29T22:23:05.965258Z","iopub.status.idle":"2025-11-29T22:23:06.038328Z","shell.execute_reply.started":"2025-11-29T22:23:05.965238Z","shell.execute_reply":"2025-11-29T22:23:06.037474Z"}},"outputs":[{"name":"stdout","text":"\n‚úÖ RESULTS\nAccuracy:  0.1874\nF1-macro:  0.1847\n\nüìä CLASSIFICATION REPORT:\n              precision    recall  f1-score   support\n\n    NEGATIVE       0.29      0.33      0.31      7725\n     NEUTRAL       0.20      0.16      0.18      7749\n    POSITIVE       0.07      0.07      0.07      7763\n\n    accuracy                           0.19     23237\n   macro avg       0.18      0.19      0.18     23237\nweighted avg       0.18      0.19      0.18     23237\n\n\nüßÆ CONFUSION MATRIX:\n[[2584 3412 1729]\n [ 749 1247 5753]\n [5638 1601  524]]\n","output_type":"stream"}],"execution_count":20}]}