# Решение команды "Шарики разума"

## Инструкция по развертыванию
Требования для запуска системы: установленные docker и python 3.13+
Для запуска приложения необходимо установить uv:

```bash
pip install uv
```

Далее необходимо синхронизировать окружение

```bash
uv sync
```

Далее необходимо настроить переменные окружения. В корне проекта требуется создать файл .env со следующим содержимым (пароли и имена пользователей могут варьироваться):
```
DB_USER=postgres
DB_PORT=5432
DB_MIGRATION_PORT=5430
DB_MIGRATION_ENGINE=postgresql
DB_PASSWORD=root
DB_NAME=reviews_analysis
DB_MIGRATION_HOST=localhost
DB_HOST=postgres

RABBITMQ_USER=admin
RABBITMQ_PASSWORD=admin123
RABBITMQ_HOST=rabbitmq
RABBITMQ_PORT=5672
RABBITMQ_VHOST=/
```

После этого необходимо запустить приложение для совершения миграций

```bash
docker compose up -d --build
```

Далее необходимо провести миграции

На Linux/MacOS:
```bash
source .venv\bin\activate
alembic upgrade head
```

На Windows:

```bash
.venv\Scripts\activate
alembic upgrade head
```

Далее необходимо получить архив с весами модели и распаковать в папку classification_models/rubert_sentiment_v2 в корне проекта. Архив можно получить по ссылке: https://disk.yandex.ru/d/Bdv9SX-qNSVlJA

После этого необходимо перезапустить приложение
```bash
docker compose down
docker compose up
```

## Участники

- Лебедев Александр (Backend-разработчик, капитан)
- Воротникова Елизавета (Frontend-разработчик)
- Захарова Дарья (Data-science-инженер)
- Ульянова Владислава (UI/UX-дизайнер)
- Рягузов Арсений (Backend-разработчик)

## Структура проекта

Проект представляет собой систему из трех сервисов:
- Сервис управления загрузками
- Сервис обработки текста
- Фронтенд-приложение

Также в системе присутствуют база данных (Postgres) и брокер очередей (RabbitMQ).

Код бекенда разбит на логику (domain, usecases) и инфраструктуру, соединяемые через адаптеры.

## Пайплайн обработки загрузки
- Пользователь выбирает документ
- Фронтенд отправляет запрос сервису управления загрузками
- Сервис управления загрузками сохраняет файл, создает запись о загрузке и публикует событие
- На событие реагирует сервис обработки текста, парсит csv-файл, создает записи текстов и валидации в БД. Публикует событие.
- На событие реагирует снова сервис обработки текстов, обрабатывает текст с помощью модели и сохраняет результат в БД пакетами по 100 текстов.

## Результаты классификации
Результаты на тестовой выборке находятся в файле predictions.csv

## Демонстрация работы
Видео с демонстрацией работы сервиса: https://disk.yandex.ru/i/Me5cBN5OQ_th7w